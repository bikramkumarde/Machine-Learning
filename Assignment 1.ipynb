{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anytree\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# foldername = \"D:\\Books VU\\2019 Fall\\CS 6362 Advanced Machine Learning\\cancer_datasets_v2\\cancer_datasets_v2\";\n",
    "data = []\n",
    "foldername = r'D:\\Books VU\\2019 Fall\\CS 6362 Advanced Machine Learning\\cancer_datasets_v2\\cancer_datasets_v2'\n",
    "\n",
    "filename = glob.glob(os.path.join(foldername,'*.csv'))\n",
    "#data = pd.read_csv(filename[2])\n",
    "#data\n",
    "#training1 = data.iloc(:, :-1).values\n",
    "#training1\n",
    "#X  = data.iloc[:, :-1].values\n",
    "\n",
    "\n",
    "# for file in foldername:\n",
    "#     for filename in glob.glob(pathname+file+\"\\\\*.csv\"):\n",
    "#         sig = []\n",
    "#         with open(filename, 'r') as fp:\n",
    "#             line = fp.readline()\n",
    "#             while(line):\n",
    "#                 amp = int(line)\n",
    "#                 sig.append(amp)\n",
    "#                 line = fp.readline()\n",
    "#         sig.append(map[file])\n",
    "#         data.append(sig)\n",
    "        \n",
    "# data = pd.DataFrame(data = data, dtype = 'float')\n",
    "# data.to_csv('epilepsy1.csv')\n",
    "\n",
    "# data = pd.read_csv('epilepsy1.csv')\n",
    "# data = data.drop(['Unnamed: 0'], axis = 1)\n",
    "# X  = data.iloc[:, :-1].values\n",
    "# #y = data.iloc[:, -1].values\n",
    "\n",
    "# s, d = X.shape\n",
    "\n",
    "# feat_X = []\n",
    "data = pd.read_csv('training_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Books VU\\\\2019 Fall\\\\CS 6362 Advanced Machine Learning\\\\cancer_datasets_v2\\\\cancer_datasets_v2\\\\testing_1.csv',\n",
       " 'D:\\\\Books VU\\\\2019 Fall\\\\CS 6362 Advanced Machine Learning\\\\cancer_datasets_v2\\\\cancer_datasets_v2\\\\testing_2.csv',\n",
       " 'D:\\\\Books VU\\\\2019 Fall\\\\CS 6362 Advanced Machine Learning\\\\cancer_datasets_v2\\\\cancer_datasets_v2\\\\training_1.csv',\n",
       " 'D:\\\\Books VU\\\\2019 Fall\\\\CS 6362 Advanced Machine Learning\\\\cancer_datasets_v2\\\\cancer_datasets_v2\\\\training_2.csv',\n",
       " 'D:\\\\Books VU\\\\2019 Fall\\\\CS 6362 Advanced Machine Learning\\\\cancer_datasets_v2\\\\cancer_datasets_v2\\\\validation_1.csv',\n",
       " 'D:\\\\Books VU\\\\2019 Fall\\\\CS 6362 Advanced Machine Learning\\\\cancer_datasets_v2\\\\cancer_datasets_v2\\\\validation_2.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateGini(p1):\n",
    "    gini = 2*p1*(1-p1)\n",
    "    return gini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateEntropy(p1):\n",
    "    entropy = -1*((p1*math.log2(p1))+((1-p1)*math.log2(1-p1)))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateInfoGain(left_p1, right_p1, left_total, right_total, root_p1):\n",
    "    left_weight = left_total/(left_total+right_total)\n",
    "    right_weight = right_total/(left_total+right_total)\n",
    "    \n",
    "    left_gini = calculateGini(left_p1)\n",
    "    right_gini = calculateGini(right_p1)\n",
    "    weighted_gini = left_weight*left_gini + right_weight*right_gini\n",
    "    root_gini = calculateGini(root_p1)\n",
    "    gain_gini = root_gini - weighted_gini\n",
    "    \n",
    "#    left_entropy = calculateEntropy(left_p1)\n",
    "#    right_entropy = calculateEntropy(right_p1)\n",
    "#    weighted_entropy = left_weight*left_entropy + right_weight*right_entropy\n",
    "#    root_entropy = calculateEntropy(root_p1)\n",
    "#    gain_entropy = root_entropy - weighted_entropy\n",
    "    \n",
    "    return gain_gini\n",
    "    #return gain_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4752120 310 23 109.4 0.35072078375080545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(310, 23, 109.4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeOptimalSplit(data):\n",
    "    max_gain = 0\n",
    "    X,Y = data.shape\n",
    "    temp_gain = K = J = max_val = 0\n",
    "    count = 0\n",
    "    data_array = data.values     #creating numpy array from dataframe\n",
    "    for j in range (1,Y):    #looping on all features(columns)\n",
    "        for i in range(0,X):     #looping on all rows\n",
    "            value = data_array[i,j]\n",
    "            left_class0 = left_class1 = right_class0 = right_class1 = 0\n",
    "            for k in range(0,X):                              \n",
    "                temp_data = data_array[k,j]\n",
    "                count += 1\n",
    "                if (temp_data<=value):\n",
    "                    if (data_array[k,0] ==0):\n",
    "                        left_class0 += 1\n",
    "                    else:\n",
    "                        left_class1 += 1\n",
    "                else:\n",
    "                    if (data_array[k,0]==0):\n",
    "                        right_class0 += 1\n",
    "                    else:\n",
    "                        right_class1 += 1\n",
    "            left_total = left_class0 + left_class1\n",
    "            right_total = right_class0 + right_class1\n",
    "#           print(left_class0, left_class1, left_total,';', right_class0, right_class1, right_total)\n",
    "            if(left_total != 0 and right_total != 0):\n",
    "                left_p1 = left_class0/left_total\n",
    "                right_p1 = right_class0/right_total\n",
    "                root_p1 = (left_class0 + right_class0)/(left_total + right_total)   #for calculating info gain of parent\n",
    "                temp_gain = calculateInfoGain(left_p1, right_p1, left_total, right_total, root_p1)\n",
    "#               print(temp_gain)\n",
    "            else:\n",
    "#                K=k\n",
    "#                J=j\n",
    "#                max_val = value     ############\n",
    "                temp_gain = 0\n",
    "            if (temp_gain > max_gain):\n",
    "                max_gain = temp_gain\n",
    "                K = i\n",
    "                J = j\n",
    "                max_val = value\n",
    "    print(count, K, J, max_val, max_gain)\n",
    "    return K, J, max_val\n",
    "data = pd.read_csv('training_1.csv')\n",
    "computeOptimalSplit(data)                \n",
    "            \n",
    "                    \n",
    "                    \n",
    "                        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoppingCond(data):\n",
    "    I,J = data.shape\n",
    "    data_array = data.values\n",
    "    sum1 = 0\n",
    "    product = 1\n",
    "    for i in range (0,I):\n",
    "        sum1 = sum1 + data_array[i,0]\n",
    "        product = product * data_array[i,0]\n",
    "    if ((sum1 == 0) or (product == 1)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4752120 310 23 109.4 0.35072078375080545\n",
      "4752120 310 23 109.4 0.35072078375080545\n",
      "310 23\n",
      "Perimeter__max\n",
      "(224, 31)\n",
      "left (224, 31)\n",
      "1505280 38 28 0.1708 0.055945789168380486\n",
      "38 28\n",
      "28\n",
      "(38, 31)\n",
      "left (38, 31)\n",
      "43320 24 14 19.75 0.024930747922437622\n",
      "24 14\n",
      "14\n",
      "(23, 31)\n",
      "Perimeter__max 109.400000\n",
      "└── Perimeter__max 109.400000\n",
      "    └── 28 0.170800\n",
      "        └── 14 19.750000\n",
      "right (86, 31)\n",
      "221880 18 8 0.04835 0.09002573310895637\n",
      "18 8\n",
      "8\n",
      "(8, 31)\n",
      "left (8, 31)\n",
      "1920 7 2 15.51 0.46875\n",
      "7 2\n",
      "2\n",
      "(2, 31)\n",
      "Perimeter__max 109.400000\n",
      "└── Perimeter__max 109.400000\n",
      "    ├── 28 0.170800\n",
      "    │   └── 14 19.750000\n",
      "    └── 8 0.048350\n",
      "        └── 2 15.510000\n",
      "right (10, 31)\n",
      "3000 5 2 13.93 0.18000000000000002\n",
      "5 2\n",
      "2\n",
      "(0, 0)\n",
      "Perimeter__max 109.400000\n",
      "└── Perimeter__max 109.400000\n",
      "    ├── 28 0.170800\n",
      "    │   └── 14 19.750000\n",
      "    └── 8 0.048350\n",
      "        ├── 2 15.510000\n",
      "        └── 2 13.930000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('training_1.csv')\n",
    "from anytree import Node, RenderTree\n",
    "K, J, max_val = computeOptimalSplit(data)\n",
    "data_array = data.values       #creating numpy array of the dataframe\n",
    "node_name = data.columns[J]    #getting the name of the feature at column J\n",
    "#print(node_name)\n",
    "#print(max_val)\n",
    "Root = Node(node_name, val = max_val)          # creating root node\n",
    "root1 = Root\n",
    "    \n",
    "\n",
    "def createSplit(data,root2):\n",
    "    from anytree import Node, RenderTree\n",
    "    K, J, max_val = computeOptimalSplit(data)\n",
    "    print(K,J)\n",
    "    data_array = data.values       #creating numpy array of the dataframe\n",
    "    node_name = data.columns[J]    #getting the name of the feature at column J\n",
    "    print(node_name)\n",
    "    root = Node(node_name, parent = root2, val = max_val)          # creating root node\n",
    "    root1 = root\n",
    "    root2 = root\n",
    "#    count = 0\n",
    "    left_data = []\n",
    "    right_data = []\n",
    "    #data = np.concatenate((data[:,0:J], data[:,(J+1):]),axis = 1)\n",
    "    for k in range(0,K):\n",
    "        \n",
    "        data1 = data.loc[k,:].values    #storing all features of a particular row\n",
    "        \n",
    "        #print(data1)\n",
    "        #print(count)\n",
    "        if (data_array[k,J]<=max_val):\n",
    "            #data1 = data.loc[k,:]\n",
    "            #count += 1\n",
    "            left_data.append(data1)\n",
    "            #print(left_data)\n",
    "        else:\n",
    "            #data2 = data.loc[k,:]\n",
    "            right_data.append(data1)\n",
    "    left_data_new = pd.DataFrame(left_data)    #creating dataframe for left and right data\n",
    "    print(left_data_new.shape)\n",
    "    right_data_new = pd.DataFrame(right_data)\n",
    "    if stoppingCond(left_data_new) != True:\n",
    "        left_data_new.drop(J, axis = 1)        #dropping Jth column from dataframe\n",
    "        print('left',left_data_new.shape)\n",
    "        #left_data = np.concatenate((left_data.loc[:,0:J], left_data.loc[:,(J+1):]),axis = 1)\n",
    "        createSplit(left_data_new, root1)\n",
    "    if stoppingCond(right_data_new) != True:\n",
    "        right_data_new.drop(J, axis = 1)\n",
    "        print('right',right_data_new.shape)\n",
    "        #right_data = np.concatenate((right_data.loc[:,0:J], right_data.loc[:,(J+1):]),axis = 1)\n",
    "        createSplit(right_data_new, root2)\n",
    "    if stoppingCond(left_data_new) == True and stoppingCond(right_data_new)== True:\n",
    "        for pre, fill, Node in RenderTree(Root):\n",
    "            print(\"%s%s %f\" %(pre, Node.name, Node.val))\n",
    "\n",
    "\n",
    "createSplit(data,root1)    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'left_data_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0077385655b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_data_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_data_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#data = pd.read_csv('training_1.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'left_data_new' is not defined"
     ]
    }
   ],
   "source": [
    "print(left_data_new.shape)\n",
    "print(right_data_new.shape)\n",
    "#data = pd.read_csv('training_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fn(data):\n",
    "    print(data.shape)\n",
    "    print(data.columns)\n",
    "    data1 = data.values\n",
    "    data1 = data.loc[1,:].values\n",
    "    print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 31)\n",
      "Index(['Is_Malignant', 'Radius__mean', 'Texture', 'Perimeter__mean',\n",
      "       'Area__mean', 'Smoothness__mean', 'Compactness__mean',\n",
      "       'Concavity__mean', 'Number_of_Concavities__mean', 'Symmetry__mean',\n",
      "       'Factal_Dimension__mean', 'Radius__stddev', 'Texture__stddev',\n",
      "       'Perimeter__stddev', 'Area__stddev', 'Smoothness__stddev',\n",
      "       'Compactness__stddev', 'Concavity__stddev',\n",
      "       'Number_of_Concavities__stddev', 'Symmetry__stddev',\n",
      "       'Factal_Dimension__stddev', 'Radius__max', 'Texture__max',\n",
      "       'Perimeter__max', 'Area__max', 'Smoothness__max', 'Compactness__max',\n",
      "       'Concavity__max', 'Number_of_Concavities__max', 'Symmetry__max',\n",
      "       'Factal_Dimension__max'],\n",
      "      dtype='object')\n",
      "[0.000e+00 1.032e+01 1.635e+01 6.531e+01 3.249e+02 9.434e-02 4.994e-02\n",
      " 1.012e-02 5.495e-03 1.885e-01 6.201e-02 2.104e-01 9.670e-01 1.356e+00\n",
      " 1.297e+01 7.086e-03 7.247e-03 1.012e-02 5.495e-03 1.560e-02 2.606e-03\n",
      " 1.125e+01 2.177e+01 7.112e+01 3.849e+02 1.285e-01 8.842e-02 4.384e-02\n",
      " 2.381e-02 2.681e-01 7.399e-02]\n"
     ]
    }
   ],
   "source": [
    "my_fn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training_1.csv')\n",
    "from anytree import Node, RenderTree\n",
    "K, J, max_val = computeOptimalSplit(data)\n",
    "data_array = data.values       #creating numpy array of the dataframe\n",
    "node_name = data.columns[J]    #getting the name of the feature at column J\n",
    "#print(node_name)\n",
    "#print(max_val)\n",
    "Root = Node(node_name, val = max_val)          # creating root node\n",
    "root1 = Root\n",
    "    \n",
    "\n",
    "def createSplit(data,root2):\n",
    "    from anytree import Node, RenderTree\n",
    "    de(node_name, parent = root1, val = max_val)\n",
    "        createSplit(left_data_new, root1)\n",
    "    if stoppingCond(right_data_new) != True:\n",
    "        right_data_new.drop(J, axis = 1)\n",
    "        print('right',right_data_new.shape)\n",
    "        #right_data = nK, J, max_val = computeOptimalSplit(data)\n",
    "    print(K,J)\n",
    "    data_array = data.values       #creating numpy array of the dataframe\n",
    "    node_name = data.columns[J]    #getting the name of the feature at column J\n",
    "    print(node_name)\n",
    "    root = Node(node_name, parent = root2, val = max_val)          # creating root node\n",
    "    root1 = root\n",
    "    root2 = root\n",
    "    left_data = []\n",
    "    right_data = []\n",
    "    for k in range(0,K):\n",
    "        \n",
    "        data1 = data.loc[k,:].values    #storing all features of a particular row\n",
    "        \n",
    "        #print(data1)\n",
    "        #print(count)\n",
    "        if (data_array[k,J]<=max_val):\n",
    "            left_data.append(data1)\n",
    "        else:\n",
    "            #data2 = data.loc[k,:]\n",
    "            right_data.append(data1)\n",
    "    left_data_new = pd.DataFrame(left_data)    #creating dataframe for left and right data\n",
    "    print(left_data_new.shape)\n",
    "    right_data_new = pd.DataFrame(right_data)\n",
    "    if stoppingCond(left_data_new) != True:\n",
    "        left_data_new.drop(J, axis = 1)        #dropping Jth column from dataframe\n",
    "        print('left',left_data_new.shape)\n",
    "        #left_data = np.concatenate((left_data.loc[:,0:J], left_data.loc[:,(J+1):]),axis = 1)\n",
    "        left_child = Nop.concatenate((right_data.loc[:,0:J], right_data.loc[:,(J+1):]),axis = 1)\n",
    "        right_child = Node(node_name, parent = root2, val = max_val)\n",
    "        createSplit(right_data_new, root2)\n",
    "    if stoppingCond(left_data_new) == True and stoppingCond(right_data_new)== True:\n",
    "        for pre, fill, Node in RenderTree(Root):\n",
    "            print(\"%s%s %f\" %(pre, Node.name, Node.val))\n",
    "\n",
    "\n",
    "createSplit(data,root1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training_1.csv')\n",
    "from anytree import Node, RenderTree\n",
    "K, J, max_val = computeOptimalSplit(data)\n",
    "data_array = data.values       #creating numpy array of the dataframe\n",
    "node_name = data.columns[J]    #getting the name of the feature at column J\n",
    "#print(node_name)\n",
    "#print(max_val)\n",
    "Root = Node(node_name, val = max_val)          # creating root node\n",
    "root1 = Root\n",
    "\n",
    "def createChild(root):\n",
    "    left_child = Node(node_name, parent = root, val = max_val_left)\n",
    "    right_child = Node(node_name, parent = root, val = max_val_right)\n",
    "    \n",
    "def createSplit(data):\n",
    "    #K, J, max_val = computeOptimalSplit(data)\n",
    "    data_array = data.values       #creating numpy array of the dataframe\n",
    "    left_data = []\n",
    "    right_data = []\n",
    "    for k in range(0,K):\n",
    "        data1 = data.loc[k,:].values    #storing all features of a particular row\n",
    "        if (data_array[k,J]<=max_val):\n",
    "            left_data.append(data1)\n",
    "        else:\n",
    "            right_data.append(data1)\n",
    "    left_data_new = pd.DataFrame(left_data)    #creating dataframe for left and right data\n",
    "    right_data_new = pd.DataFrame(right_data)\n",
    "    left_data_new.drop(J, axis = 1)        #dropping Jth column from dataframe\n",
    "    right_data_new.drop(J, axis = 1)\n",
    "    \n",
    "    K_right, J_right, max_val_right = computeOptimalSplit(right_data_new)\n",
    "    \n",
    "    if stoppingCond(left_data_new) != True:\n",
    "        K_left, J_left, max_val_left = computeOptimalSplit(left_data_new)\n",
    "\n",
    "        \n",
    "        left_child = Node(node_name, parent = root1, val = max_val)\n",
    "        createSplit(left_data_new, root1)\n",
    "    if stoppingCond(right_data_new) != True:\n",
    "\n",
    "        print('right',right_data_new.shape)\n",
    "        #right_data = np.concatenate((right_data.loc[:,0:J], right_data.loc[:,(J+1):]),axis = 1)\n",
    "        right_child = Node(node_name, parent = root2, val = max_val)\n",
    "        createSplit(right_data_new, root2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f57ac22ab9dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0manytree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDotExporter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mDotExporter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRoot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_picture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Root.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\anytree\\exporter\\dotexporter.py\u001b[0m in \u001b[0;36mto_picture\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mNamedTemporaryFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdotfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mdotfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdotfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                 \u001b[0mdotfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mdotfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\anytree\\exporter\\dotexporter.py\u001b[0m in \u001b[0;36m__iter\u001b[1;34m(self, indent, nodenamefunc, nodeattrfunc, edgeattrfunc, edgetypefunc)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0moption\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodenamefunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodeattrfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0medge\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodenamefunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgeattrfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgetypefunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\anytree\\exporter\\dotexporter.py\u001b[0m in \u001b[0;36m__iter_nodes\u001b[1;34m(self, indent, nodenamefunc, nodeattrfunc)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mnodeattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodeattrfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mnodeattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" [%s]\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnodeattr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnodeattr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;34m'%s\"%s\"%s;'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDotExporter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mesc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodeattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodenamefunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgeattrfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgetypefunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\anytree\\exporter\\dotexporter.py\u001b[0m in \u001b[0;36mesc\u001b[1;34m(str)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mesc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;34m\"\"\"Escape Strings.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\\\\\\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "from anytree.exporter import DotExporter\n",
    "DotExporter(Root).to_picture(\"Root.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training_1.csv')\n",
    "data_array = data.values \n",
    "def createData(data):\n",
    "    K, J, max_val = computeOptimalSplit(data)\n",
    "    print(K,J)\n",
    "    data_array = data.values       #creating numpy array of the dataframe\n",
    "    node_name = data.columns[J]    #getting the name of the feature at column J\n",
    "    left_data = []\n",
    "    right_data = []\n",
    "    for k in range(0,K):\n",
    "        data1 = data.loc[k,:].values    #storing all features of a particular row\n",
    "        if (data_array[k,J]<=max_val):\n",
    "            left_data.append(data1)\n",
    "        else:\n",
    "            right_data.append(data1)\n",
    "    left_data_new = pd.DataFrame(left_data, columns = data.columns)    #creating dataframe for left and right data\n",
    "    right_data_new = pd.DataFrame(right_data, columns = data.columns)\n",
    "    if stoppingCond(left_data_new) != True:\n",
    "        left_data_new_modified = left_data_new.drop(node_name, axis = 1)        #dropping Jth column from dataframe\n",
    "    if stoppingCond(right_data_new) != True:\n",
    "        right_data_new_modified = right_data_new.drop(node_name, axis = 1)\n",
    "    return left_data_new_modified, right_data_new_modified, node_name, max_val\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4752120 310 23 109.4 0.35072078375080545\n",
      "310 23\n",
      "4752120 310 23 109.4 0.35072078375080545\n",
      "310 23\n",
      "1455104 38 27 0.1708 0.055945789168380486\n",
      "214484 18 8 0.04835 0.09002573310895637\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-13275c061cb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mdata_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m       \u001b[1;31m#creating numpy array of the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mnode_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m#getting the name of the feature at column J\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mbuild_recurse_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-13275c061cb5>\u001b[0m in \u001b[0;36mbuild_recurse_tree\u001b[1;34m(node, data)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mK_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeOptimalSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mK_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeOptimalSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdframe2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_recurse_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_recurse_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdframe2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'dframe'"
     ]
    }
   ],
   "source": [
    "class Node():\n",
    "    def __init__(self, dframe, attribute, threshold, info):\n",
    "        self.dframe = dframe\n",
    "        self.attribute = str(attribute)\n",
    "        self.threshold = threshold\n",
    "        self.info = info\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "        \n",
    "def build_recurse_tree(node, data):            \n",
    "    if stoppingCond(data):\n",
    "        print('node is pure')               \n",
    "    else:\n",
    "        #split\n",
    "        dframe, dframe2, attribute, threshold = createData(data)\n",
    "        K_left, J_left, val_left = computeOptimalSplit(dframe)\n",
    "        K_right, J_right, val_right = computeOptimalSplit(dframe2)\n",
    "        node.left = build_recurse_tree(Node(node.dframe, node.attribute, node.threshold, (2*node.info)),dframe)\n",
    "        node.right = build_recurse_tree(Node(node.dframe, node.attribute, node. threshold, (2*node.info+1)),dframe2)\n",
    "        return node\n",
    "K, J, max_val = computeOptimalSplit(data)\n",
    "print(K,J)\n",
    "data_array = data.values       #creating numpy array of the dataframe\n",
    "node_name = data.columns[J]    #getting the name of the feature at column J    \n",
    "build_recurse_tree(node_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
